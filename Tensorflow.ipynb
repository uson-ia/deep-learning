{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probando Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST (beginners)\n",
    "\n",
    "Script para descargar los datos de MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los datos se dividen en 2 matrices, una de datos para entrenar (mnist.train) y otra para probar nuestro\n",
    "aprendizaje (mnist.test).\n",
    "La matriz train cuenta con 55000 imagenes de 28x28 pixeles, es decir, 55000 vectores de tamano 784 que representan\n",
    "imagenes de digitos escritos a mano. La matriz `mnist.train.label` es la que indica que digito es cada imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la matriz de imagenes >>  (55000, 784)\n",
      "Dimension de la matriz de labels >>  (55000, 10)\n",
      "Dimensiones de la matriz de prueba >>  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print \"Dimensiones de la matriz de imagenes >> \", mnist.train.images.shape\n",
    "print \"Dimension de la matriz de labels >> \", mnist.train.labels.shape\n",
    "print \"Dimensiones de la matriz de prueba >> \", mnist.test.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presicion con nuestros datos de entrenamiento >>  0.9189\n"
     ]
    }
   ],
   "source": [
    "# x es solo un placeholder, es decir no tiene un valor especifico aun\n",
    "x = tf.placeholder(\"float\", [None, 784])   # La dimension de x, es (lo que sea, 784)\n",
    "W = tf.Variable(tf.zeros([784,10]))        # Pesos\n",
    "b = tf.Variable(tf.zeros([10]))            # Bias\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)      # Predicted probability\n",
    "\n",
    "y_ = tf.placeholder(\"float\", [None,10]) \n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)    # Minimizamos con descenso de\n",
    "# gradiente, con un grado de aprendizaje de 0.01\n",
    "\n",
    "# Inicializamos las variables que creamos\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# Entrenamos con 1000 iteraciones\n",
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))    # Acertamos ?\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))   # Con que exactitud ?\n",
    "\n",
    "print \"Presicion con nuestros datos de entrenamiento >> \", sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deep MINST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision con nuestros datos de prueba >>  0.9139\n"
     ]
    }
   ],
   "source": [
    "# Tensorflow utiliza un backend en C++ para hacer el computa mas eficiente.\n",
    "# Para establecer una coneccion con este backend usaremos una sesion.\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\n",
    "# Nodos para las imagenes de entrada y las clases de salida objetivo\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "# pesos y bias ('tensors' de puros ceros hasta ahora)\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "# inicializamos las variables previas definidas para poder usarlas\n",
    "# se inician dentro de la sesion que creamos\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# ahora implementamos nuestro modelo de regresion (softmax)\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "# especificamos nuestra funcion costo a minimizar, la cual sera\n",
    "# 'cross-entropy' entre los objetivos y nuestra prediccion de modelo\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# usamos descenso de gradiente para minimizar la entropia y repetimos\n",
    "# esto con un epoc de 1000\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "for i in range(1000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "    \n",
    "# checamos que tan bien le fue a nuestro modelo comparando\n",
    "# la etiqueta que nuestro modelo dice es la mas probable para cada entrada\n",
    "# con la etiqueta correcta.\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "\n",
    "# como 'correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))' nos\n",
    "# dara una lista de booleanos, convertiremos la lista a 0's y 1's y \n",
    "# despues le sacamos la media\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# ahora evaluamos nuestra precision con los datos de prueba\n",
    "print \"Precision con nuestros datos de prueba >> \", accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multilayer Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# esta funcion regresa una matriz con pesos iniciales\n",
    "# aleatorios provenientes de una distribucion normal\n",
    "# con desviacion estandar = .1\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# esta funcion regresa una matriz con todos los elementos\n",
    "# igual a .1 y dimensiones = shape\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestras funciones de convolucion y pooling maximo de bloques de 2x2. Las usaremos mas adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primera capa convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta capa se procesan 32 caracteristicas por cada pieza de datos de 5x5.\n",
    "\n",
    "Tambien creamos un vector de bias por cada salida (de las 32). Para esto usamos las funciones creadas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le hacemos reshape a x, haciendo un tensor 4d. La segunda y tercera dimension corresponden al ancho y alto de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la funcion rectificadora al vector x convolucionado con el vector de pesos, al mismo tiempo se le anade el ruido.\n",
    "\n",
    "Despues aplicamos el max pooling sobre una region de 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creando otra capa mas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos otra capa mas de convolucion para crear la red profunda.\n",
    "\n",
    "Esta capa tendra 64 caracteristicas por cada bloque de 5x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos una capota completamente conectada, con 1024 neuronas que procesaran toda la imagen. Primero creamos el vector de pesos con la imagen reducida a 7x7, luego creamos el vector con los bias. Redimensionamos el tensor de la capa de pooling en un \"lote\" de vectores. Por ultimo lo multiplicamos por la matriz de pesos (anadiendole el bias), y a eso le aplicamos la funcion de activacion rectificadora. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para reducir el sobre-aprendizaje, aplicaremos algo como regularizacion en redes neuronales, un concepto bastante interesante, el \"dropout\", que es, en algunos casos, poniendo algunas unidades de activacion en cierta capa a cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente creamos una capa mas con una regresion softmax, con sus respectivos pesos y bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluacion del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Para entrenar y evaluar nuestro modelo usaremos codigo muy parecido al de la regresion Softmax pasada, la diferencia es que reemplazaremos el descenso de gradiente con un optimizador mas sofisticado, ADAM, incluimos tambien `keep_prob` dentro del diccionario `feed_dict` para controlar la tasa de dropout. Cada 100 iteraciones calculamos la precision de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteracion 0, precision de entrenamiento 0.16\n",
      "Iteracion 100, precision de entrenamiento 0.9\n",
      "Iteracion 200, precision de entrenamiento 0.8\n",
      "Iteracion 300, precision de entrenamiento 0.96\n",
      "Iteracion 400, precision de entrenamiento 0.96\n",
      "Iteracion 500, precision de entrenamiento 0.98\n",
      "Iteracion 600, precision de entrenamiento 0.98\n",
      "Iteracion 700, precision de entrenamiento 0.98\n",
      "Iteracion 800, precision de entrenamiento 0.96\n",
      "Iteracion 900, precision de entrenamiento 0.94\n",
      "Iteracion 1000, precision de entrenamiento 0.98\n",
      "Iteracion 1100, precision de entrenamiento 0.96\n",
      "Iteracion 1200, precision de entrenamiento 0.96\n",
      "Iteracion 1300, precision de entrenamiento 0.98\n",
      "Iteracion 1400, precision de entrenamiento 0.94\n",
      "Iteracion 1500, precision de entrenamiento 1\n",
      "Iteracion 1600, precision de entrenamiento 0.96\n",
      "Iteracion 1700, precision de entrenamiento 1\n",
      "Iteracion 1800, precision de entrenamiento 0.96\n",
      "Iteracion 1900, precision de entrenamiento 0.96\n",
      "Iteracion 2000, precision de entrenamiento 0.96\n",
      "Iteracion 2100, precision de entrenamiento 0.96\n",
      "Iteracion 2200, precision de entrenamiento 0.98\n",
      "Iteracion 2300, precision de entrenamiento 0.94\n",
      "Iteracion 2400, precision de entrenamiento 0.98\n",
      "Iteracion 2500, precision de entrenamiento 1\n",
      "Iteracion 2600, precision de entrenamiento 0.94\n",
      "Iteracion 2700, precision de entrenamiento 1\n",
      "Iteracion 2800, precision de entrenamiento 0.98\n",
      "Iteracion 2900, precision de entrenamiento 0.98\n",
      "Iteracion 3000, precision de entrenamiento 1\n",
      "Iteracion 3100, precision de entrenamiento 0.96\n",
      "Iteracion 3200, precision de entrenamiento 1\n",
      "Iteracion 3300, precision de entrenamiento 1\n",
      "Iteracion 3400, precision de entrenamiento 0.98\n",
      "Iteracion 3500, precision de entrenamiento 1\n",
      "Iteracion 3600, precision de entrenamiento 0.94\n",
      "Iteracion 3700, precision de entrenamiento 1\n",
      "Iteracion 3800, precision de entrenamiento 0.98\n",
      "Iteracion 3900, precision de entrenamiento 0.98\n",
      "Iteracion 4000, precision de entrenamiento 1\n",
      "Iteracion 4100, precision de entrenamiento 0.98\n",
      "Iteracion 4200, precision de entrenamiento 1\n",
      "Iteracion 4300, precision de entrenamiento 0.98\n",
      "Iteracion 4400, precision de entrenamiento 1\n",
      "Iteracion 4500, precision de entrenamiento 0.98\n",
      "Iteracion 4600, precision de entrenamiento 1\n",
      "Iteracion 4700, precision de entrenamiento 1\n",
      "Iteracion 4800, precision de entrenamiento 1\n",
      "Iteracion 4900, precision de entrenamiento 1\n",
      "Iteracion 5000, precision de entrenamiento 1\n",
      "Iteracion 5100, precision de entrenamiento 1\n",
      "Iteracion 5200, precision de entrenamiento 1\n",
      "Iteracion 5300, precision de entrenamiento 0.98\n",
      "Iteracion 5400, precision de entrenamiento 1\n",
      "Iteracion 5500, precision de entrenamiento 0.98\n",
      "Iteracion 5600, precision de entrenamiento 1\n",
      "Iteracion 5700, precision de entrenamiento 0.98\n",
      "Iteracion 5800, precision de entrenamiento 1\n",
      "Iteracion 5900, precision de entrenamiento 1\n",
      "Iteracion 6000, precision de entrenamiento 1\n",
      "Iteracion 6100, precision de entrenamiento 1\n",
      "Iteracion 6200, precision de entrenamiento 0.98\n",
      "Iteracion 6300, precision de entrenamiento 1\n",
      "Iteracion 6400, precision de entrenamiento 1\n",
      "Iteracion 6500, precision de entrenamiento 0.98\n",
      "Iteracion 6600, precision de entrenamiento 1\n",
      "Iteracion 6700, precision de entrenamiento 0.98\n",
      "Iteracion 6800, precision de entrenamiento 0.98\n",
      "Iteracion 6900, precision de entrenamiento 1\n",
      "Iteracion 7000, precision de entrenamiento 0.98\n",
      "Iteracion 7100, precision de entrenamiento 0.98\n",
      "Iteracion 7200, precision de entrenamiento 1\n",
      "Iteracion 7300, precision de entrenamiento 0.98\n",
      "Iteracion 7400, precision de entrenamiento 1\n",
      "Iteracion 7500, precision de entrenamiento 0.96\n",
      "Iteracion 7600, precision de entrenamiento 0.98\n",
      "Iteracion 7700, precision de entrenamiento 0.96\n",
      "Iteracion 7800, precision de entrenamiento 1\n",
      "Iteracion 7900, precision de entrenamiento 1\n",
      "Iteracion 8000, precision de entrenamiento 1\n",
      "Iteracion 8100, precision de entrenamiento 1\n",
      "Iteracion 8200, precision de entrenamiento 0.98\n",
      "Iteracion 8300, precision de entrenamiento 1\n",
      "Iteracion 8400, precision de entrenamiento 1\n",
      "Iteracion 8500, precision de entrenamiento 1\n",
      "Iteracion 8600, precision de entrenamiento 0.98\n",
      "Iteracion 8700, precision de entrenamiento 1\n",
      "Iteracion 8800, precision de entrenamiento 1\n",
      "Iteracion 8900, precision de entrenamiento 1\n",
      "Iteracion 9000, precision de entrenamiento 1\n",
      "Iteracion 9100, precision de entrenamiento 1\n",
      "Iteracion 9200, precision de entrenamiento 1\n",
      "Iteracion 9300, precision de entrenamiento 0.96\n",
      "Iteracion 9400, precision de entrenamiento 0.98\n",
      "Iteracion 9500, precision de entrenamiento 1\n",
      "Iteracion 9600, precision de entrenamiento 1\n",
      "Iteracion 9700, precision de entrenamiento 1\n",
      "Iteracion 9800, precision de entrenamiento 1\n",
      "Iteracion 9900, precision de entrenamiento 0.98\n",
      "Iteracion 10000, precision de entrenamiento 1\n",
      "Iteracion 10100, precision de entrenamiento 1\n",
      "Iteracion 10200, precision de entrenamiento 0.98\n",
      "Iteracion 10300, precision de entrenamiento 1\n",
      "Iteracion 10400, precision de entrenamiento 1\n",
      "Iteracion 10500, precision de entrenamiento 1\n",
      "Iteracion 10600, precision de entrenamiento 1\n",
      "Iteracion 10700, precision de entrenamiento 1\n",
      "Iteracion 10800, precision de entrenamiento 1\n",
      "Iteracion 10900, precision de entrenamiento 1\n",
      "Iteracion 11000, precision de entrenamiento 1\n",
      "Iteracion 11100, precision de entrenamiento 1\n",
      "Iteracion 11200, precision de entrenamiento 1\n",
      "Iteracion 11300, precision de entrenamiento 1\n",
      "Iteracion 11400, precision de entrenamiento 1\n",
      "Iteracion 11500, precision de entrenamiento 0.98\n",
      "Iteracion 11600, precision de entrenamiento 1\n",
      "Iteracion 11700, precision de entrenamiento 1\n",
      "Iteracion 11800, precision de entrenamiento 1\n",
      "Iteracion 11900, precision de entrenamiento 1\n",
      "Iteracion 12000, precision de entrenamiento 1\n",
      "Iteracion 12100, precision de entrenamiento 1\n",
      "Iteracion 12200, precision de entrenamiento 1\n",
      "Iteracion 12300, precision de entrenamiento 1\n",
      "Iteracion 12400, precision de entrenamiento 1\n",
      "Iteracion 12500, precision de entrenamiento 1\n",
      "Iteracion 12600, precision de entrenamiento 1\n",
      "Iteracion 12700, precision de entrenamiento 1\n",
      "Iteracion 12800, precision de entrenamiento 1\n",
      "Iteracion 12900, precision de entrenamiento 0.98\n",
      "Iteracion 13000, precision de entrenamiento 0.98\n",
      "Iteracion 13100, precision de entrenamiento 1\n",
      "Iteracion 13200, precision de entrenamiento 1\n",
      "Iteracion 13300, precision de entrenamiento 0.98\n",
      "Iteracion 13400, precision de entrenamiento 1\n",
      "Iteracion 13500, precision de entrenamiento 0.98\n",
      "Iteracion 13600, precision de entrenamiento 1\n",
      "Iteracion 13700, precision de entrenamiento 0.98\n",
      "Iteracion 13800, precision de entrenamiento 1\n",
      "Iteracion 13900, precision de entrenamiento 1\n",
      "Iteracion 14000, precision de entrenamiento 1\n",
      "Iteracion 14100, precision de entrenamiento 1\n",
      "Iteracion 14200, precision de entrenamiento 1\n",
      "Iteracion 14300, precision de entrenamiento 1\n",
      "Iteracion 14400, precision de entrenamiento 1\n",
      "Iteracion 14500, precision de entrenamiento 1\n",
      "Iteracion 14600, precision de entrenamiento 0.98\n",
      "Iteracion 14700, precision de entrenamiento 1\n",
      "Iteracion 14800, precision de entrenamiento 0.98\n",
      "Iteracion 14900, precision de entrenamiento 1\n",
      "Iteracion 15000, precision de entrenamiento 1\n",
      "Iteracion 15100, precision de entrenamiento 1\n",
      "Iteracion 15200, precision de entrenamiento 1\n",
      "Iteracion 15300, precision de entrenamiento 1\n",
      "Iteracion 15400, precision de entrenamiento 1\n",
      "Iteracion 15500, precision de entrenamiento 1\n",
      "Iteracion 15600, precision de entrenamiento 1\n",
      "Iteracion 15700, precision de entrenamiento 1\n",
      "Iteracion 15800, precision de entrenamiento 1\n",
      "Iteracion 15900, precision de entrenamiento 1\n",
      "Iteracion 16000, precision de entrenamiento 1\n",
      "Iteracion 16100, precision de entrenamiento 1\n",
      "Iteracion 16200, precision de entrenamiento 1\n",
      "Iteracion 16300, precision de entrenamiento 0.98\n",
      "Iteracion 16400, precision de entrenamiento 0.98\n",
      "Iteracion 16500, precision de entrenamiento 1\n",
      "Iteracion 16600, precision de entrenamiento 1\n",
      "Iteracion 16700, precision de entrenamiento 1\n",
      "Iteracion 16800, precision de entrenamiento 1\n",
      "Iteracion 16900, precision de entrenamiento 1\n",
      "Iteracion 17000, precision de entrenamiento 0.98\n",
      "Iteracion 17100, precision de entrenamiento 1\n",
      "Iteracion 17200, precision de entrenamiento 1\n",
      "Iteracion 17300, precision de entrenamiento 1\n",
      "Iteracion 17400, precision de entrenamiento 1\n",
      "Iteracion 17500, precision de entrenamiento 1\n",
      "Iteracion 17600, precision de entrenamiento 1\n",
      "Iteracion 17700, precision de entrenamiento 1\n",
      "Iteracion 17800, precision de entrenamiento 1\n",
      "Iteracion 17900, precision de entrenamiento 1\n",
      "Iteracion 18000, precision de entrenamiento 1\n",
      "Iteracion 18100, precision de entrenamiento 1\n",
      "Iteracion 18200, precision de entrenamiento 1\n",
      "Iteracion 18300, precision de entrenamiento 1\n",
      "Iteracion 18400, precision de entrenamiento 1\n",
      "Iteracion 18500, precision de entrenamiento 1\n",
      "Iteracion 18600, precision de entrenamiento 1\n",
      "Iteracion 18700, precision de entrenamiento 1\n",
      "Iteracion 18800, precision de entrenamiento 1\n",
      "Iteracion 18900, precision de entrenamiento 1\n",
      "Iteracion 19000, precision de entrenamiento 1\n",
      "Iteracion 19100, precision de entrenamiento 1\n",
      "Iteracion 19200, precision de entrenamiento 1\n",
      "Iteracion 19300, precision de entrenamiento 1\n",
      "Iteracion 19400, precision de entrenamiento 1\n",
      "Iteracion 19500, precision de entrenamiento 1\n",
      "Iteracion 19600, precision de entrenamiento 1\n",
      "Iteracion 19700, precision de entrenamiento 1\n",
      "Iteracion 19800, precision de entrenamiento 1\n",
      "Iteracion 19900, precision de entrenamiento 1\n",
      "Exactitud de prueba 0.9913\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"Iteracion %d, precision de entrenamiento %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"Exactitud de prueba %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
