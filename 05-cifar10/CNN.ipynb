{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Redes Neuronales Convolucionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este tutorial es para raza bien pesada en machine learning :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Descripcion General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clasificacion CIFAR-10 es un problema comun de benchmark en machine learning. El problema es clasificar las imagenes RGB de 32 X 32 pixeles en las siguientes 10 categorias: Avion, Carro, Pajaro, Gato, Venado, Perro, Rana, Caballo, Barco y Trailers.\n",
    "\n",
    "![Image of Yaktocat](https://www.tensorflow.org/versions/master/images/cifar_samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Objetivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este tutorial es construir relativamente una pequena Red Neuronal Convolucional para reconocer imagenes. En el proceso de este tutorial:\n",
    "\n",
    "1. Se resalta una organizacion canonical para la arquitectura de red, entrenamiento y evaluacion.\n",
    "2. Provee un template para construir un modelo mas grande y sofisticado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Aspectos destacados del Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tutorial CIFAR-10 demuestra varias construcciones importantes para un disenio grande y modelos mas sofisticados en TensorFlow:\n",
    "\n",
    "* Componentes matematicos basicos incluidos tales como convolution, rectified linear activations, max pooling y local response normalization.\n",
    "* Visualizacion de la red de actividades durante el entrenamiento incluyendo imagenes de entrada, perdidas y distribuciones de activacion y gradientes.\n",
    "* Rutinas para calcular el moving average de los parametros de aprendisaje utilizando estos promedios durante la evaluacion para aumentar el rendimiento de prediccion.\n",
    "* Implementacion de un learning rate schedule que sistematicamente decrese sobre el tiempo.\n",
    "* Prefetching queues para los datos de entrada para isolar el modelo de la latencia del disco y el preprocesamiento de imagenes costosas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Arquitectura del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo en este tutorial de CIFAR-10 es una arquitectura multicapas que consiste de convoluciones alternas y nonlinearities. Estas capas estan seguidas de capas fully connected dirigidas dentro del clasifiador softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Organizacion del Codigo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El codigo de este tutorial se encuentra en el github del proyecto.\n",
    "\n",
    "Los archivos a utilizar son los siguientes:\n",
    "\n",
    "* cifar10_input.py - Lee el formato nativo en binario del archivo CIFAR-10.\n",
    "* cifar10.py - Construye el modelo CIFAR-10\n",
    "* cifar10_train.py - Entrena el modelo CIFAR-10 en un CPU.\n",
    "* cifar10_eval.py - Evalua el rendimiento de la exactitud de el Modelo CIFAR-10.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Modelo CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red CIFAR-10 esta contenida en gran parte en cifar10.py. El entrenamiento completo del grafo contiene aproximadamente 765 operaciones. El codigo se puede hacer mas reutilizable mediante la construccion en el grafo de los siguientes modulos:\n",
    "\n",
    "1. Model inputs: inputs() y distorted_inputs() agrega operaciones que leen el preprocesamiento de las imagenes de CIFAR para la evaluacion y entrenamiento respectivamente.\n",
    "2. Model prediction: inference() agrega operaciones que realizan inferencia por ejemplo clasificacion, en las imagenes dadas.\n",
    "3. Model training: loss() y train() agrega operaciones que calculan la perdida, gradientes, actualizaciones de variables y visualizacion de recopilatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Entradas del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La parte de entrada del modelo es contruido por las funciones inputs() y distorted_inputs() lo cual leen imagenes de los archivos de datos binarios de CIFAR-10. Estos archivos contienen registros de bytes de longitud fija entonces se usa tf.FixedLengthRecordReader.\n",
    "\n",
    "Las imagenes son procesadas de la siguiente manera:\n",
    "\n",
    "* Las imagenes se recortan a un tamanio de 24 X 24 pixeles centralmente para la evaluacion aleatoria en el entrenamiento.\n",
    "* Las imagenes estan aproximadamente whitened para hacer el modelo insensible en el rango dinamico.\n",
    "\n",
    "Para entrenamiento adicionalmente se aplican series de distiorsiones aleatorias para incrementar artificialmente el tamanio del dataset:\n",
    "\n",
    "* Se voltea aleatoriamente la imagen de izquierda a derecha.\n",
    "* Se distorciona aleatoriamente el brillo de la imagen.\n",
    "* Se distorciona aleatoriamente el contraste de la imagen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prediccion del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La parte de la prediccion del modelo se contruye con la funcion de inference() la cual agrega operaciones para calcular los logits de las predicciones. Esta parte del modelo se organiza como sigue:\n",
    "\n",
    "Nombre de la capa - Descripcion\n",
    "* conv1             - Convolution y rectified linear activation.\n",
    "* pool1             - max polling.\n",
    "* norm1             - local response normalization.\n",
    "* conv2             - convolution y rectified linear activation.\n",
    "* norm2             - local response normalization.\n",
    "* pool2             - max pooling.\n",
    "* local3            - fully connected layer with rectified linear activation.\n",
    "* local4            - fully connected layer with rectified linear activation.\n",
    "* softmax_linear    - Transformacion lineal que produce logits.\n",
    "\n",
    "Aqui se presenta el grafo el cual fue generado por TensorBoard el cual describe la operacion de inferencia:\n",
    "\n",
    "![Image of Yaktocat](https://www.tensorflow.org/versions/master/images/cifar_graph.png)\n",
    "\n",
    "Las funciones inputs() y inference() proveen todos los componentes necesarios para realizar la evaluacion de un modelo. Ahora se cambiara el enfoque hacia las operaciones de construccion para el entrenamiento de un modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El metodo usual para entrenar una red es realizar la clasificacion N-Way la cual es una regresion logistica multinomial regresion softmax. La regresion Softmax aplica un softmax nonlinearity a la salida de la red y calcula la cross-entropy entre las predicciones normalizadas y un 1-hot codificado de la etiqueta. Para la regularizacion se aplica usualmente la perdida de weight decay para todas las variables de aprendisaje. La funcion objetivo para el modelo es la suma de perdida de cross-entropy y todos sus pesos en terminos de decadencia esto se regresa con la funcion loss().\n",
    "\n",
    "Se puede visualizar la perdida total en el TensorBoard con un scalar_summary:\n",
    "\n",
    "![Image of Yaktocat](https://www.tensorflow.org/versions/master/images/cifar_loss.png)\n",
    "\n",
    "Se entrena el modelo usando el algoritmo de descenso de gradiente estandar con una taza de aprendisaje que decae exponencialmente sobre el tiempo.\n",
    "\n",
    "![Image of Yaktocat](https://www.tensorflow.org/versions/master/images/cifar_lr_decay.png)\n",
    "\n",
    "La funcion train() agrega las operaciones necesarias para minimizar el objetivo tal que calcula el gradiente y actualiza las variables de aprendisaje. Regresa una operacion que ejecuta todos los calculos necesarios para entrenar y actualizar el modelo para un batch de imagenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Inicializando y Entrenando el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que se construyo el modelo se pasa a inicializarlo y ejecutar la operacion de entrenamiento con el script cifar10_train.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading cifar-10-binary.tar.gz 20.3%"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filepath='/home/juanmanuel/Desktop/deep-learning/cifar10'\n",
    "os.chdir(filepath)\n",
    "%run cifar10_train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
