{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#MNIST Para Principiantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta libreta se sigue el tutorial de MNIST For ML Beginners presentado en el proyecto de TensorFlow.\n",
    "\n",
    "Los objetivos de este tutorial es conocer que es MNIST ademas de la regresion softmax.\n",
    "\n",
    "MNIST es un dataset de vision por computadora. Consiste en imagenes de digitos escritos a mano tambien incluye etiquetas de cada imagen donde el nombre de cada etiqueta es el digito que se presenta en la imagen.\n",
    "\n",
    "Ademas en este tutorial se ve un modelo de entrenamiento que revisa las imagenes y predice que digitos hay en ellas dicho modelo se llama regresion softmax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Los Datos de MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de MNIST se descargan mediante el archivo que se encuentra en el proyecto TensorFlow en github llamado input_data.py\n",
    "este archivo descarga los datos que se tratan en tres partes diferentes las cuales son:\n",
    "\n",
    "* mnist.train (Contiene 55,00 puntos de datos de entrenamiento)\n",
    "* mnist.test (Contiene 10.000 puntos de datos de prueba)\n",
    "* mnist.validation (Contiene 5.000 puntos de datos de validación)\n",
    "\n",
    "En machine learning es importante tener los datos de forma separada para que con los datos que se aprenda se pueda generalizar.\n",
    "\n",
    "Como se menciona arriba el dataset MNIST consta de dos partes una es la imagen del digito escrito a mano y la otra la etiqueta con el nombre del correspondiente digito en la imagen a estos dos valores se les llamara \"xs\" y \"ys\" donde xs representa las imagenes y ys las etiquetas. Los datos de mnist.train y mnist.test contienen los valores de xs y ys.\n",
    "\n",
    "Cada imagen es de tamano de 28 x 28 pixeles lo cual se puede interpretar como un vector con 784 numeros.\n",
    "\n",
    "El resultado es que mnist.train.images es un tensor (Un arreglo de dimension n) con el siguiente tamano [55000, 784]. El primer indice corresponde al indice de las imagenes y el segundo indice a el tamano en pixeles que tiene cada imagen. \n",
    "\n",
    "Cada posicion en el tensor representa un pixel que se encuentra en una imagen cada pixel tiene un valor en el rango de 0 a 1.\n",
    "\n",
    "Las etiquetas en MNIST estan en el rango de 0-9 los cuales son los digitos que pueden contener estas imagenes. Para utilizar las etiquetas se utiliza \"one-hot vectors\" lo cual es un vector que en la mayoria de sus dimensiones contiene un 0 y en una dimension tiene un valor unico en este caso 1. \n",
    "\n",
    "Por ejemplo si se tiene la etiqueta 3 se representa por el siguiente vector [0, 0, 0, 1, 0, 0, 0, 0, 0].\n",
    "\n",
    "A continuacion se muestra el codigo para descargar los datos de MNIST. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Regresión Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se sabe que en MNIST cada imagen representa un digito el cual esta en el rango de 0-9. La idea de utilizar un modelo de entrenamiento que por ejemplo dada una imagen de MNIST que contenga por decir un 9 se pueda decir con cierta probabilidad que digito le corresponde a dicha imagen se espera que el modelo de una probabilidad muy alta de que sea el valor 9 pero tambien se puede esperar una probabilidad pequena de que sea un 8 y una mas pequena probabilidad de que sea otro digito.\n",
    "\n",
    "Este es un caso clasico de una regresion softmax en donde se busca asignar probabilidades a un objeto o a diferentes cosas.\n",
    "\n",
    "Una regresion softmax consiste de dos pasos:\n",
    "\n",
    "1) Se agrega la evidencia que se tiene en ciertas clases.\n",
    "2) Se convierte dicha evidencia en probabilidades.\n",
    "\n",
    "Para determinar si una imagen pertenece a una clase en especial se utiliza una suma ponderada en donde se cuentan la intensidad de los pixeles si la suma ponderada da un valor negativo para una clase en particular significa que la imagen no pertenece a esa clase y si da positivo significa que puede pertenecer a esa clase.\n",
    "\n",
    "Ademas se necesita una evidencia extra a la cual se le llama bias. Basicamanete se quiere decir que algunas cosas son independientes de la entrada. El resultado es la evidencia para una clase i dada una entrada x es:\n",
    "\n",
    "$$\\text{evidence}_i = \\sum_j W_{i,~ j} x_j + b_i$$\n",
    "\n",
    "donde wi son los pesos y bi es el bias para la clase i, ademas j es el indice para la suma de los pixeles en la entrada de la imagen x.\n",
    "\n",
    "Se convierte la evidencia en probabilidades predecidas por la regresion softmax:\n",
    "\n",
    "$$y = \\text{softmax}(\\text{evidence})$$\n",
    "\n",
    "Aqui la regresion softmax sirve como una funcion de activacion dando forma a la salida de la funcion lineal a utilizar en la forma que se desea en este caso una distribucion de probabilidad con 10 casos.\n",
    "\n",
    "La funcion softmax se define como:\n",
    "\n",
    "$$\\text{softmax}(x) = \\text{normalize}(\\exp(x))$$\n",
    "\n",
    "Si se expande la ecuacion se obtiene:\n",
    "\n",
    "$$\\text{softmax}(x)_i = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$\n",
    "\n",
    "La exponenciación significa que una unidad mas de evidencia incrementa el peso para cualquier hipotesis caso contrario una unidad menos de evidencia decrementa el peso para cualquier hipotesis. Ninguna hipotesis tendra el valor 0 o un valor negativo. La regresion softmax normaliza los pesos gracias a esto se tiene una distribucion valida de probabilidad.\n",
    "\n",
    "La regresion softmax se puede ver de la siguiente forma: \n",
    "\n",
    "![Image of Yaktocat](https://www.tensorflow.org/versions/master/images/softmax-regression-scalargraph.png)\n",
    "\n",
    "Las salidas de la regresion softmax se pueden escribir de la siguiente manera:\n",
    "\n",
    "![Image of Yaktocat](https://www.tensorflow.org/versions/master/images/softmax-regression-scalarequation.png)\n",
    "\n",
    "Tambien se puede vectorizar el procedimiento anterior transformandolo en una multiplicacion de matrices y la suma de un vector como se ve a continuacion:\n",
    "\n",
    "\n",
    "![Image of Yaktocat](https://www.tensorflow.org/versions/master/images/softmax-regression-vectorequation.png)\n",
    "\n",
    "Se puede escribir mas compacto como por ejemplo:\n",
    "\n",
    "$$y = \\text{softmax}(Wx + b)$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Implementando la regresion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza TensorFlow el cual utiliza operaciones interactivas que se ejecutan fuera de python a continuacion se importa la libreria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se describen estas operaciones manipulando variables simbolicas se procede a crear una:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x no es un valor en especifico. Es un placeholder, un valor que se pondra cuando se le pida a TensorFlow ejecutar alguna instruccion.\n",
    "\n",
    "Tambien se necesitan los pesos y el bias para el modelo de regresion softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A este tipo de variables se les da un valor inicial en este caso se inicializan ambos tensores w y b con valores de 0. Se procede aprender W y b por lo que no importa mucho con que valores se inicializen.\n",
    "\n",
    "Como nota el tamano de W es [784, 10] porque se quiere multiplicar los vectores de 784 dimensiones para podrucir 10 vectores de pruebas para las clases de diferencia.\n",
    "\n",
    "Ahora se puede implementar el modelo el cual solo toma una linea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, se multiplica x por W con la expresion tf.matmul(x, W). Despues se suma b el cual es el bias y finalmente se aplica tf.nn.softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer para entrenar el modelo se necesita definir que significa un buen modelo. En machine learning actualmente se define que significa un mal modelo para esto se consideran los aspectos siguientes como el costo y la perdida y se trata de minimizar ambos aspectos. Los dos son queivalentes.\n",
    "\n",
    "Una de las funciones mas comunes para costo es \"cross-entropy\" la cual se usa para codigos de comprension de informacion en la teoria de informacion pero esta idea se utiliza en muchas areas esta funcion se define a continuacion:\n",
    "\n",
    "$$H_{y'}(y) = -\\sum_i y'_i \\log(y_i)$$\n",
    "\n",
    "donde y es la prediccion de la distribucion de probabilidad y y' es la verdadera distribucion (El \"one-hot vectors\" que se dio en la entrada).\n",
    "\n",
    "Para implementar cross-entropy se necesita primero agregar un nuevo placeholder pra la entrada de las respuestas correctas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se puede implementar cross-entropy $$-\\sum y'\\log(y)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero, tf.log calcula el logatitmo de cada elemento de y. Luego multiplica cada elemento de y_ con el correspondiente elemento de tf.log(y). Finalmente se suman todos los elementos al tensor con tf.reduce_sum\n",
    "(Nota: Si se utiliza cross_entropy para un solo valor no da una descripcion muy buena por lo que se utiliza la suma de 100 cross-entropy esto da una mejor descripcion de que tan bueno es el modelo a utilizar.)\n",
    "\n",
    "Ahora que se sabe que se desea del modelo es facil entrenarlo con TensorFlow ya que sabe el grafo completo de los calculos que se han hecho se usa automaticamente el algoritmo de backpropagation para determinar como afecta el costo de las variables que se utilizan y se pregunta como minimizar. Despues se aplica algun algoritmo de optimizacion para modificar las variables y reducir el costo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se le pregunta a TensorFlow como minimizar cross_entropy usando el algoritmo de descenso de gradiente con una taza de aprendisaje de 0.01. El descenso de gradiente es un simple procedimiento donde TensorFlow simplemente cambia cada variable un poco de tal forma que se reduzca el costo. \n",
    "\n",
    "Lo que hace TensorFlow actualmente es regresar a escenas pasadas y agregar nuevas operaciones al grafo para implementar backpropagation y descenso de gradiente. Con esto se obtiene una sola operacion que cuando se ejecuta va a un paso en el algoritmo de descenso de gradiente y reduce su costo.\n",
    "\n",
    "Se tiene ahora el modelo a utilizar pero para empezar se inicializan todas las variables que se crearon.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion se va entrenar con 1000 iteraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada iteracion del loop se obtiene un batch de 100 puntos de datos aleatorios para el conjunto de entrenamiento. \n",
    "Se ejecuta train_step para dar feeding en los batches y reemplazar los placeholders.\n",
    "\n",
    "Usar pequenos batches aleatorios de datos se le llama entrenamiento estocastico. En este caso el descenso de gradiente estocastico. Lo ideal seria utilizar toda la informacion que se tiene al entrnar ya que daria un mejor sentido a lo que se esta haciendo pero como es costoso mejor se utilizan diferentes subconjuntos cada vez esto es barato y se obtiene un beneficio parecido al otro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Evaluando el Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Que tan bueno es el modelo?\n",
    "\n",
    "Bueno primero se va a predecir la etiqueta correcta. tf.argmax es una funcion muy util la cual regresa el indice mas alto en la posicion de un tensor a lo largo de un eje. Por ejemplo tf.argmax(y, 1) es la etiqueta del modelo que peinsa que es el valor mas probable para cada posicion. mientras que tf.argmax(y_. 1) es la etiqueta correcta. Se puede utilizar tf.equal para revisar si la prediccion concuerda con la verdad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La instruccion anterior regresa una lista de valores bool. Para determinar que fraccion de valores son correctos se aplica un cast con valores de punto flotante y luego se calcula la media.\n",
    "\n",
    "Por ejemplo supongamos que obtenemos la siguiente lista [True, False, True, True] aplicando el cast se convierte en la siguiente lista [1, 0, 1, 1] y la media obtenida es 0.75.\n",
    "\n",
    "Se muestra el codigo que realiza las operaciones dichas previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente se obtiene la exactidud al probar los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor obtenido se debe de encontrar cerca del 91%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es bueno? de entrada parece que si pero en realidad no. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
