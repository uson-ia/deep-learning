{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Para Principiantes\n",
    "\n",
    "En esta libreta se realizara el tutorial de MNIST del TensorFlow. Puedes verlo dando clic [aqui](URL \"https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html\").\n",
    "\n",
    "El objetivo de realizar esta libreta es de ver la capacidad del TensorFlow.\n",
    "\n",
    "MNIST es un sistema simple que trabaja con un conjunto de datos que consisten en imagenes escritas a mano como estos:\n",
    "\n",
    "![Image](https://www.tensorflow.org/versions/master/images/MNIST.png)\n",
    "\n",
    "Tambien incluye etiquetas por cada imagen, diciendo que digito es que. por ejemplo las etiquetas de las imagenes de arriba serian 5, 0, 4 y 1.\n",
    "\n",
    "En este Tutorial vamos a entrenar un modelo para que vea unas imagenes y predecira que digito son. \n",
    "\n",
    "\n",
    "## The MNIST Data\n",
    "\n",
    "Los datos Para el MNIST se descaragan con el achivo **input_data.py** que se ejecuta de la siguiente forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La informacion descargada es separada en 3 partes, 55,000 datos para entrenamiento, 10,000 datos para prueba y 5,000 datos para validacion. esta separacion es muy importante: es escencial en machine learning separar la informacion con la que no aprendemos para verificar que de verdad aprendimos.\n",
    "\n",
    "Como se menciono anteriormente, cada dato en el MNIST tiene dos partes: una imagen de algun digito escrito a mano y una etiqueta de a que valor corresponde. Llamaremos a estas imagenes \"xs\" y a las etiquetas \"ys\". tanto como el set de entrenamiento como el de prueva contienen xs y ys, por ejemplo las imagenes de entrenamiento son **mnist.train.images** y las etiquetas de entrenamiento son **mnist.train.labels**.\n",
    "\n",
    "Cada imagen es de 28x28 pixeles, donde esto se puede interpretar como una vector de numeros.\n",
    "\n",
    "![](https://www.tensorflow.org/versions/master/images/MNIST-Matrix.png)\n",
    "\n",
    "El resultado que **mnist.train.images** es un tensor(un arreglo n dimensional) con una forma de **[55000, 784]**. la primer dimension es para indexar las imagenes y la segunda para los pixeles de cada imagen. cada entrada en el tensor es la intensidad del pixel con valor entre 0 y 1.\n",
    "\n",
    "![](https://www.tensorflow.org/versions/master/images/mnist-train-xs.png)\n",
    "\n",
    "Las etiquetas correspondientes en el MNIST son numeros entre 0 y 9, diciendo que digito es dado a cada imagen. Para el proposito de este tutorial, vamos a querer que nuestras etiquetas como un \"one-hot vectors\". esto es un vector que es 0 en casi todas las dimensiones y 1 en solo una dimension. en este caso el n-esimo digito va a ser representado como un vector en donde es uno en la n-esima dimension. por ejemplo 3 seria **[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]**. Por lo tanto, **mnist.train.labels** ss un arreglo de flotantes de la forma **[55000, 10]**.\n",
    "\n",
    "![](https://www.tensorflow.org/versions/master/images/mnist-train-ys.png)\n",
    "\n",
    "Ahora ya estamos listos para hacer nuestro modelo!\n",
    "\n",
    "\n",
    "# Implementando Regresion Softmax\n",
    "\n",
    "Se importa el TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un placeholder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x es donde se guardara la instruccion para el tensorflow por eso es un placeholder.\n",
    "\n",
    "Tabien necesitamos pesos y bias para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estas variables se les da un valor inicial de 0 en todo sus puntos.\n",
    "\n",
    "Ahora podemos implementar nuestro modelo utilizando solamente una linea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero multiplicamos x por W, despues se suma b al resultado y despues se aplica la funcion softmax de tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento\n",
    "\n",
    "para entrenar nuestro modelo, necesitamos definir que significa que el modelo sea bueno.\n",
    "\n",
    "para esto vamos a ulizar una distribucion conocida como cross-entropy que mide que tan ineficiente son nuestras predicciones para decir la verdad.\n",
    "\n",
    "para implementar el cross-entropy necesitamos a√±adir un nuevo placeholder para poner la respuesta correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despues implementamos el cross-entropy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero tf.log calcula el logaritmo de cada elemento de y, despues multiplicamos cada elemento de y_ con su elemento correspondiente en tf.log(y). por ultimo tf.reduce_sum suma todos los elementos del tensor.\n",
    "\n",
    "ahora que ya se sabe que es lo que queremos que realize nuestro modelo es muy facil entrenar al tensorflow.\n",
    "vamos a utilizar el algoritmo de backpropagation para determinar eficientemente como nuestras variables afectan el costo que pides minimizar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de que le pidamos al TensorFlow que minimize el cross_entropy utilizando el algoritmo de decenso de gradiente con un aprendizaje del 0.01.\n",
    "\n",
    "ahora tenemos nuestro modelo listo para entrenar. nomas falta agregar una operacion para inicializar todas las variables que hemos creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora iniciamos nuestro modelo en una **Session** y ejecutamos la operacion que inicializa las variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entenar 1000 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En cada iteracion se obtiene un batch de 100 datos al azar para el conjunto de entrenamiento. Ejecutamos **train_step** para alimentar los batches reemplazando los placeholders.\n",
    "\n",
    "# Evaluando el Modelo\n",
    "\n",
    "Primero vamos a predecir donde se predijo una etiqueta correcta. **tf.argmax** es una funcion muy util que te da el indice de la entrada mas alta en el tensor asi como su posicion. podemos utilizar  **tf.equal** para checar si nuestras predicciones son correctas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos da una lista de booleanos. para determinar que partes estan correctas, llamamos a la media de estos puntos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ultimo, pedimos la exactitud de los datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es cerca del 91%\n",
    "\n",
    "Esto no es bueno ya que si hubieramos utilizado otro modelo o hubieramos hecho algunos cambios en este, habria aumentado bastante hasta tener una precision de 99.7% por ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
